{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1b9fce9a7c53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mclass_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"class_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-8341c59f38ae>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kaiser_fast'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mmfccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmfccsscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '../dataset/audio/'\n",
    "\n",
    "#metadata = pd.read_csv('../dataset/dataset.csv')\n",
    "metadata = pd.read_csv('../dataset/datasetM2.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class_name\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_train' (ndarray)\n",
      "Stored 'x_test' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n",
      "Stored 'yy' (ndarray)\n",
      "Stored 'le' (LabelEncoder)\n"
     ]
    }
   ],
   "source": [
    "### store the preprocessed data for use in the next notebook\n",
    "\n",
    "%store x_train \n",
    "%store x_test \n",
    "%store y_train \n",
    "%store y_test \n",
    "%store yy \n",
    "%store le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,858\n",
      "Trainable params: 78,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 5.9701%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 267 samples, validate on 67 samples\n",
      "Epoch 1/350\n",
      "267/267 [==============================] - 0s 635us/step - loss: 84.1730 - accuracy: 0.1236 - val_loss: 33.5022 - val_accuracy: 0.1045\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 33.50217, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 2/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 59.2097 - accuracy: 0.2135 - val_loss: 16.6402 - val_accuracy: 0.1194\n",
      "\n",
      "Epoch 00002: val_loss improved from 33.50217 to 16.64023, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 3/350\n",
      "267/267 [==============================] - 0s 95us/step - loss: 46.2892 - accuracy: 0.2022 - val_loss: 10.4291 - val_accuracy: 0.2687\n",
      "\n",
      "Epoch 00003: val_loss improved from 16.64023 to 10.42911, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 4/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 38.6799 - accuracy: 0.1835 - val_loss: 8.0916 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00004: val_loss improved from 10.42911 to 8.09158, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 5/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 33.6602 - accuracy: 0.1685 - val_loss: 5.6810 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.09158 to 5.68102, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 6/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 22.4930 - accuracy: 0.2434 - val_loss: 3.8180 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.68102 to 3.81798, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 7/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 17.4590 - accuracy: 0.2472 - val_loss: 3.6676 - val_accuracy: 0.1940\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.81798 to 3.66755, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 8/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 15.6186 - accuracy: 0.2060 - val_loss: 2.4259 - val_accuracy: 0.1642\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.66755 to 2.42592, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 9/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 12.7526 - accuracy: 0.2547 - val_loss: 2.2026 - val_accuracy: 0.1343\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.42592 to 2.20259, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 10/350\n",
      "267/267 [==============================] - 0s 106us/step - loss: 11.0171 - accuracy: 0.2397 - val_loss: 2.1190 - val_accuracy: 0.1194\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.20259 to 2.11899, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 11/350\n",
      "267/267 [==============================] - 0s 129us/step - loss: 8.3781 - accuracy: 0.2285 - val_loss: 2.1158 - val_accuracy: 0.1045\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.11899 to 2.11576, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 12/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 7.2041 - accuracy: 0.2397 - val_loss: 2.1552 - val_accuracy: 0.1493\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.11576\n",
      "Epoch 13/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 5.9014 - accuracy: 0.2247 - val_loss: 2.1793 - val_accuracy: 0.1791\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.11576\n",
      "Epoch 14/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 5.4761 - accuracy: 0.2247 - val_loss: 2.1876 - val_accuracy: 0.1791\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.11576\n",
      "Epoch 15/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 5.3735 - accuracy: 0.2322 - val_loss: 2.2021 - val_accuracy: 0.1791\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.11576\n",
      "Epoch 16/350\n",
      "267/267 [==============================] - 0s 129us/step - loss: 5.0229 - accuracy: 0.2097 - val_loss: 2.2074 - val_accuracy: 0.1791\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.11576\n",
      "Epoch 17/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 3.9272 - accuracy: 0.2322 - val_loss: 2.2144 - val_accuracy: 0.1642\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.11576\n",
      "Epoch 18/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 3.6220 - accuracy: 0.2060 - val_loss: 2.2145 - val_accuracy: 0.1493\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.11576\n",
      "Epoch 19/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 3.5767 - accuracy: 0.2060 - val_loss: 2.2166 - val_accuracy: 0.1493\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.11576\n",
      "Epoch 20/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 3.4625 - accuracy: 0.2434 - val_loss: 2.2107 - val_accuracy: 0.1343\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.11576\n",
      "Epoch 21/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 3.2852 - accuracy: 0.2622 - val_loss: 2.2094 - val_accuracy: 0.1493\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.11576\n",
      "Epoch 22/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 2.8797 - accuracy: 0.2697 - val_loss: 2.1942 - val_accuracy: 0.1940\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.11576\n",
      "Epoch 23/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 3.0352 - accuracy: 0.1910 - val_loss: 2.1544 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.11576\n",
      "Epoch 24/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 2.6269 - accuracy: 0.2921 - val_loss: 2.1187 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.11576\n",
      "Epoch 25/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 2.6769 - accuracy: 0.2509 - val_loss: 2.1090 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.11576 to 2.10895, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 26/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 2.6822 - accuracy: 0.2509 - val_loss: 2.0826 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.10895 to 2.08255, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 27/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 2.6106 - accuracy: 0.2360 - val_loss: 2.0318 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.08255 to 2.03176, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 28/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 2.5184 - accuracy: 0.2322 - val_loss: 2.0294 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.03176 to 2.02944, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 29/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 2.5302 - accuracy: 0.2547 - val_loss: 2.0281 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.02944 to 2.02806, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 30/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 2.5978 - accuracy: 0.2509 - val_loss: 2.0055 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.02806 to 2.00548, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 31/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 2.2897 - accuracy: 0.2846 - val_loss: 1.9996 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.00548 to 1.99963, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 32/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 2.5589 - accuracy: 0.2210 - val_loss: 1.9959 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.99963 to 1.99586, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 33/350\n",
      "267/267 [==============================] - 0s 146us/step - loss: 2.3612 - accuracy: 0.2996 - val_loss: 2.0103 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.99586\n",
      "Epoch 34/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 2.1760 - accuracy: 0.2996 - val_loss: 2.0351 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.99586\n",
      "Epoch 35/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 2.3277 - accuracy: 0.3184 - val_loss: 2.0397 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.99586\n",
      "Epoch 36/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 2.2954 - accuracy: 0.2959 - val_loss: 2.0228 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.99586\n",
      "Epoch 37/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 2.1592 - accuracy: 0.2996 - val_loss: 2.0156 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.99586\n",
      "Epoch 38/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 2.2185 - accuracy: 0.2959 - val_loss: 2.0062 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.99586\n",
      "Epoch 39/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 2.1431 - accuracy: 0.3408 - val_loss: 1.9827 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.99586 to 1.98268, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 40/350\n",
      "267/267 [==============================] - 0s 119us/step - loss: 2.2223 - accuracy: 0.2996 - val_loss: 1.9430 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.98268 to 1.94297, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 41/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 2.2446 - accuracy: 0.2622 - val_loss: 1.9394 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.94297 to 1.93942, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 42/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 2.2558 - accuracy: 0.2809 - val_loss: 1.9462 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.93942\n",
      "Epoch 43/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 2.3061 - accuracy: 0.2884 - val_loss: 1.9375 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.93942 to 1.93750, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 44/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 2.0719 - accuracy: 0.2996 - val_loss: 1.9130 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.93750 to 1.91299, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 45/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 2.1886 - accuracy: 0.3146 - val_loss: 1.8875 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.91299 to 1.88751, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 46/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 2.4079 - accuracy: 0.2809 - val_loss: 1.9028 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.88751\n",
      "Epoch 47/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 2.1158 - accuracy: 0.3071 - val_loss: 1.9138 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.88751\n",
      "Epoch 48/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 2.1851 - accuracy: 0.2697 - val_loss: 1.9232 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.88751\n",
      "Epoch 49/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 2.0219 - accuracy: 0.3034 - val_loss: 1.9034 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.88751\n",
      "Epoch 50/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 2.0914 - accuracy: 0.3221 - val_loss: 1.8835 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.88751 to 1.88350, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 51/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 2.0846 - accuracy: 0.3071 - val_loss: 1.8883 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.88350\n",
      "Epoch 52/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 2.1152 - accuracy: 0.3146 - val_loss: 1.8952 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.88350\n",
      "Epoch 53/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9738 - accuracy: 0.3258 - val_loss: 1.8898 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.88350\n",
      "Epoch 54/350\n",
      "267/267 [==============================] - 0s 153us/step - loss: 2.0971 - accuracy: 0.3221 - val_loss: 1.8857 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.88350\n",
      "Epoch 55/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 2.0256 - accuracy: 0.3146 - val_loss: 1.8652 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.88350 to 1.86525, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 56/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 2.0869 - accuracy: 0.3184 - val_loss: 1.8495 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.86525 to 1.84950, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 57/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 2.0826 - accuracy: 0.2921 - val_loss: 1.8462 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.84950 to 1.84624, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 58/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 2.1018 - accuracy: 0.2996 - val_loss: 1.8599 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.84624\n",
      "Epoch 59/350\n",
      "267/267 [==============================] - 0s 94us/step - loss: 1.9309 - accuracy: 0.3558 - val_loss: 1.8657 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.84624\n",
      "Epoch 60/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 2.0702 - accuracy: 0.3146 - val_loss: 1.8395 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.84624 to 1.83951, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 61/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.9726 - accuracy: 0.3596 - val_loss: 1.8225 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.83951 to 1.82250, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 62/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 2.0270 - accuracy: 0.3633 - val_loss: 1.7817 - val_accuracy: 0.3731\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.82250 to 1.78171, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 63/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.9444 - accuracy: 0.3221 - val_loss: 1.7790 - val_accuracy: 0.3582\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.78171 to 1.77897, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 64/350\n",
      "267/267 [==============================] - 0s 113us/step - loss: 1.9749 - accuracy: 0.3521 - val_loss: 1.7896 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.77897\n",
      "Epoch 65/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9245 - accuracy: 0.3296 - val_loss: 1.7772 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.77897 to 1.77717, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 66/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.9626 - accuracy: 0.3446 - val_loss: 1.7845 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.77717\n",
      "Epoch 67/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 1.9439 - accuracy: 0.3146 - val_loss: 1.7653 - val_accuracy: 0.3582\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.77717 to 1.76526, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 68/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 2.0340 - accuracy: 0.3521 - val_loss: 1.7715 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.76526\n",
      "Epoch 69/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.9334 - accuracy: 0.3146 - val_loss: 1.7962 - val_accuracy: 0.3731\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.76526\n",
      "Epoch 70/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.9532 - accuracy: 0.3221 - val_loss: 1.7986 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.76526\n",
      "Epoch 71/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.9367 - accuracy: 0.3109 - val_loss: 1.8369 - val_accuracy: 0.1791\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.76526\n",
      "Epoch 72/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 2.0501 - accuracy: 0.2659 - val_loss: 1.7733 - val_accuracy: 0.3433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_loss did not improve from 1.76526\n",
      "Epoch 73/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9500 - accuracy: 0.3296 - val_loss: 1.7379 - val_accuracy: 0.4179\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.76526 to 1.73787, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 74/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 1.8599 - accuracy: 0.3783 - val_loss: 1.7622 - val_accuracy: 0.3731\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.73787\n",
      "Epoch 75/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 2.0861 - accuracy: 0.3034 - val_loss: 1.8074 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.73787\n",
      "Epoch 76/350\n",
      "267/267 [==============================] - 0s 114us/step - loss: 1.8758 - accuracy: 0.3558 - val_loss: 1.7970 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.73787\n",
      "Epoch 77/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.8743 - accuracy: 0.3670 - val_loss: 1.7669 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.73787\n",
      "Epoch 78/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9652 - accuracy: 0.3558 - val_loss: 1.7446 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.73787\n",
      "Epoch 79/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.9461 - accuracy: 0.3596 - val_loss: 1.7499 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.73787\n",
      "Epoch 80/350\n",
      "267/267 [==============================] - 0s 104us/step - loss: 1.9078 - accuracy: 0.3221 - val_loss: 1.7607 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.73787\n",
      "Epoch 81/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.8880 - accuracy: 0.3184 - val_loss: 1.7977 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.73787\n",
      "Epoch 82/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9477 - accuracy: 0.3371 - val_loss: 1.8048 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.73787\n",
      "Epoch 83/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 2.0294 - accuracy: 0.3333 - val_loss: 1.7798 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.73787\n",
      "Epoch 84/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.8796 - accuracy: 0.3408 - val_loss: 1.7453 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.73787\n",
      "Epoch 85/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.9231 - accuracy: 0.3408 - val_loss: 1.7663 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.73787\n",
      "Epoch 86/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.8942 - accuracy: 0.3258 - val_loss: 1.7973 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.73787\n",
      "Epoch 87/350\n",
      "267/267 [==============================] - 0s 94us/step - loss: 1.9309 - accuracy: 0.3333 - val_loss: 1.8281 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.73787\n",
      "Epoch 88/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.8835 - accuracy: 0.3296 - val_loss: 1.8318 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.73787\n",
      "Epoch 89/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9785 - accuracy: 0.3071 - val_loss: 1.8007 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.73787\n",
      "Epoch 90/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.8589 - accuracy: 0.3446 - val_loss: 1.7593 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.73787\n",
      "Epoch 91/350\n",
      "267/267 [==============================] - 0s 94us/step - loss: 1.9711 - accuracy: 0.3296 - val_loss: 1.7453 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.73787\n",
      "Epoch 92/350\n",
      "267/267 [==============================] - 0s 88us/step - loss: 1.8387 - accuracy: 0.3408 - val_loss: 1.7644 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.73787\n",
      "Epoch 93/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.8169 - accuracy: 0.3446 - val_loss: 1.7790 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.73787\n",
      "Epoch 94/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.8549 - accuracy: 0.3446 - val_loss: 1.7786 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.73787\n",
      "Epoch 95/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.8372 - accuracy: 0.3895 - val_loss: 1.7558 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.73787\n",
      "Epoch 96/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.9076 - accuracy: 0.3258 - val_loss: 1.7302 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.73787 to 1.73018, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 97/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.8971 - accuracy: 0.3109 - val_loss: 1.7567 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.73018\n",
      "Epoch 98/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.8080 - accuracy: 0.3333 - val_loss: 1.7482 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.73018\n",
      "Epoch 99/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.7846 - accuracy: 0.3333 - val_loss: 1.7177 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.73018 to 1.71768, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 100/350\n",
      "267/267 [==============================] - 0s 94us/step - loss: 1.8426 - accuracy: 0.3483 - val_loss: 1.7416 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.71768\n",
      "Epoch 101/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.7462 - accuracy: 0.3670 - val_loss: 1.7398 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.71768\n",
      "Epoch 102/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.8729 - accuracy: 0.3558 - val_loss: 1.7336 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.71768\n",
      "Epoch 103/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.8129 - accuracy: 0.3333 - val_loss: 1.7208 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.71768\n",
      "Epoch 104/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.8714 - accuracy: 0.3558 - val_loss: 1.7135 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00104: val_loss improved from 1.71768 to 1.71355, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 105/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.8474 - accuracy: 0.3558 - val_loss: 1.6830 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00105: val_loss improved from 1.71355 to 1.68296, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 106/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.8845 - accuracy: 0.3446 - val_loss: 1.6883 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.68296\n",
      "Epoch 107/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.8145 - accuracy: 0.3408 - val_loss: 1.6986 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.68296\n",
      "Epoch 108/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.8048 - accuracy: 0.3483 - val_loss: 1.6888 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.68296\n",
      "Epoch 109/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.7342 - accuracy: 0.3670 - val_loss: 1.6637 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00109: val_loss improved from 1.68296 to 1.66373, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 110/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.7851 - accuracy: 0.3446 - val_loss: 1.6506 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00110: val_loss improved from 1.66373 to 1.65064, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 111/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.8641 - accuracy: 0.3408 - val_loss: 1.6469 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00111: val_loss improved from 1.65064 to 1.64694, saving model to saved_models/weights.best.basic_mlp.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.8791 - accuracy: 0.3521 - val_loss: 1.6658 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.64694\n",
      "Epoch 113/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.7222 - accuracy: 0.3970 - val_loss: 1.6751 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.64694\n",
      "Epoch 114/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.8074 - accuracy: 0.3258 - val_loss: 1.6813 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.64694\n",
      "Epoch 115/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.7471 - accuracy: 0.3633 - val_loss: 1.6907 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.64694\n",
      "Epoch 116/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.7649 - accuracy: 0.3745 - val_loss: 1.6723 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.64694\n",
      "Epoch 117/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.7189 - accuracy: 0.3895 - val_loss: 1.6411 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00117: val_loss improved from 1.64694 to 1.64111, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 118/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.9163 - accuracy: 0.3446 - val_loss: 1.6554 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.64111\n",
      "Epoch 119/350\n",
      "267/267 [==============================] - 0s 78us/step - loss: 1.8200 - accuracy: 0.3558 - val_loss: 1.6806 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.64111\n",
      "Epoch 120/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.7369 - accuracy: 0.3670 - val_loss: 1.6637 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.64111\n",
      "Epoch 121/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.7640 - accuracy: 0.3221 - val_loss: 1.6628 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.64111\n",
      "Epoch 122/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.7344 - accuracy: 0.3633 - val_loss: 1.6524 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.64111\n",
      "Epoch 123/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.7159 - accuracy: 0.3670 - val_loss: 1.6237 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.64111 to 1.62370, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 124/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.6944 - accuracy: 0.3858 - val_loss: 1.5958 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00124: val_loss improved from 1.62370 to 1.59575, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 125/350\n",
      "267/267 [==============================] - 0s 103us/step - loss: 1.7883 - accuracy: 0.3446 - val_loss: 1.5951 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.59575 to 1.59507, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 126/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.7069 - accuracy: 0.3596 - val_loss: 1.5973 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.59507\n",
      "Epoch 127/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.6969 - accuracy: 0.3820 - val_loss: 1.5905 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00127: val_loss improved from 1.59507 to 1.59047, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 128/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.8056 - accuracy: 0.3708 - val_loss: 1.5952 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.59047\n",
      "Epoch 129/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.7174 - accuracy: 0.3670 - val_loss: 1.6254 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.59047\n",
      "Epoch 130/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 1.7156 - accuracy: 0.3596 - val_loss: 1.6460 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.59047\n",
      "Epoch 131/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.7180 - accuracy: 0.3858 - val_loss: 1.6286 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.59047\n",
      "Epoch 132/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.7277 - accuracy: 0.3521 - val_loss: 1.6087 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.59047\n",
      "Epoch 133/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.7134 - accuracy: 0.3670 - val_loss: 1.5985 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.59047\n",
      "Epoch 134/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.6860 - accuracy: 0.3895 - val_loss: 1.5962 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.59047\n",
      "Epoch 135/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.7402 - accuracy: 0.3783 - val_loss: 1.6150 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.59047\n",
      "Epoch 136/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.7014 - accuracy: 0.3783 - val_loss: 1.6066 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.59047\n",
      "Epoch 137/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.7093 - accuracy: 0.3858 - val_loss: 1.5868 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00137: val_loss improved from 1.59047 to 1.58679, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 138/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.7272 - accuracy: 0.3221 - val_loss: 1.6042 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.58679\n",
      "Epoch 139/350\n",
      "267/267 [==============================] - 0s 152us/step - loss: 1.6783 - accuracy: 0.3783 - val_loss: 1.6189 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.58679\n",
      "Epoch 140/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.6995 - accuracy: 0.3745 - val_loss: 1.5949 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.58679\n",
      "Epoch 141/350\n",
      "267/267 [==============================] - 0s 133us/step - loss: 1.6878 - accuracy: 0.3895 - val_loss: 1.5768 - val_accuracy: 0.3134\n",
      "\n",
      "Epoch 00141: val_loss improved from 1.58679 to 1.57682, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 142/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.7221 - accuracy: 0.3633 - val_loss: 1.5884 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.57682\n",
      "Epoch 143/350\n",
      "267/267 [==============================] - 0s 78us/step - loss: 1.6150 - accuracy: 0.3745 - val_loss: 1.5951 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.57682\n",
      "Epoch 144/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.6540 - accuracy: 0.3633 - val_loss: 1.6024 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.57682\n",
      "Epoch 145/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.7155 - accuracy: 0.3708 - val_loss: 1.6074 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.57682\n",
      "Epoch 146/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.6647 - accuracy: 0.3670 - val_loss: 1.5861 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.57682\n",
      "Epoch 147/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 1.7077 - accuracy: 0.3408 - val_loss: 1.5789 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.57682\n",
      "Epoch 148/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.6589 - accuracy: 0.3670 - val_loss: 1.5737 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00148: val_loss improved from 1.57682 to 1.57366, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 149/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.6398 - accuracy: 0.3858 - val_loss: 1.5624 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00149: val_loss improved from 1.57366 to 1.56235, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 150/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.5994 - accuracy: 0.3745 - val_loss: 1.5363 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00150: val_loss improved from 1.56235 to 1.53633, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 151/350\n",
      "267/267 [==============================] - 0s 178us/step - loss: 1.6216 - accuracy: 0.3933 - val_loss: 1.5356 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00151: val_loss improved from 1.53633 to 1.53558, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 152/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 1.6856 - accuracy: 0.3745 - val_loss: 1.5545 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.53558\n",
      "Epoch 153/350\n",
      "267/267 [==============================] - 0s 104us/step - loss: 1.6036 - accuracy: 0.3895 - val_loss: 1.5598 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.53558\n",
      "Epoch 154/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.6663 - accuracy: 0.3633 - val_loss: 1.5734 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.53558\n",
      "Epoch 155/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.7551 - accuracy: 0.3745 - val_loss: 1.5637 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.53558\n",
      "Epoch 156/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.6654 - accuracy: 0.3858 - val_loss: 1.5453 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.53558\n",
      "Epoch 157/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.6307 - accuracy: 0.3483 - val_loss: 1.5458 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.53558\n",
      "Epoch 158/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 1.5727 - accuracy: 0.4045 - val_loss: 1.5359 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.53558\n",
      "Epoch 159/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.6369 - accuracy: 0.3783 - val_loss: 1.5345 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00159: val_loss improved from 1.53558 to 1.53451, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 160/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.5986 - accuracy: 0.3895 - val_loss: 1.5139 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00160: val_loss improved from 1.53451 to 1.51385, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 161/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.6476 - accuracy: 0.3858 - val_loss: 1.4787 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00161: val_loss improved from 1.51385 to 1.47866, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 162/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.6030 - accuracy: 0.4045 - val_loss: 1.4791 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.47866\n",
      "Epoch 163/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 1.6134 - accuracy: 0.3633 - val_loss: 1.4866 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.47866\n",
      "Epoch 164/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.5377 - accuracy: 0.4195 - val_loss: 1.4683 - val_accuracy: 0.3284\n",
      "\n",
      "Epoch 00164: val_loss improved from 1.47866 to 1.46826, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 165/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.5849 - accuracy: 0.3783 - val_loss: 1.4673 - val_accuracy: 0.3731\n",
      "\n",
      "Epoch 00165: val_loss improved from 1.46826 to 1.46725, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 166/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.5857 - accuracy: 0.3895 - val_loss: 1.4710 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.46725\n",
      "Epoch 167/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.6222 - accuracy: 0.3483 - val_loss: 1.4498 - val_accuracy: 0.3582\n",
      "\n",
      "Epoch 00167: val_loss improved from 1.46725 to 1.44975, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 168/350\n",
      "267/267 [==============================] - 0s 135us/step - loss: 1.5469 - accuracy: 0.4157 - val_loss: 1.4489 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00168: val_loss improved from 1.44975 to 1.44893, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 169/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 1.5808 - accuracy: 0.4457 - val_loss: 1.4433 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00169: val_loss improved from 1.44893 to 1.44325, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 170/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.5587 - accuracy: 0.4232 - val_loss: 1.4367 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00170: val_loss improved from 1.44325 to 1.43671, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 171/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.5406 - accuracy: 0.3895 - val_loss: 1.4070 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00171: val_loss improved from 1.43671 to 1.40705, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 172/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.5174 - accuracy: 0.4195 - val_loss: 1.3998 - val_accuracy: 0.4478\n",
      "\n",
      "Epoch 00172: val_loss improved from 1.40705 to 1.39984, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 173/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.4734 - accuracy: 0.4382 - val_loss: 1.4012 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.39984\n",
      "Epoch 174/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 1.5954 - accuracy: 0.4045 - val_loss: 1.4133 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.39984\n",
      "Epoch 175/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.5409 - accuracy: 0.4045 - val_loss: 1.4176 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.39984\n",
      "Epoch 176/350\n",
      "267/267 [==============================] - 0s 153us/step - loss: 1.5326 - accuracy: 0.4157 - val_loss: 1.4412 - val_accuracy: 0.3433\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.39984\n",
      "Epoch 177/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 1.5429 - accuracy: 0.4457 - val_loss: 1.4242 - val_accuracy: 0.3731\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.39984\n",
      "Epoch 178/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.5315 - accuracy: 0.4232 - val_loss: 1.4092 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.39984\n",
      "Epoch 179/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.5598 - accuracy: 0.3745 - val_loss: 1.3949 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00179: val_loss improved from 1.39984 to 1.39494, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 180/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.6135 - accuracy: 0.4157 - val_loss: 1.3994 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.39494\n",
      "Epoch 181/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.5399 - accuracy: 0.4307 - val_loss: 1.3876 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00181: val_loss improved from 1.39494 to 1.38761, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 182/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.5061 - accuracy: 0.4082 - val_loss: 1.3750 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00182: val_loss improved from 1.38761 to 1.37505, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 183/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 1.5147 - accuracy: 0.3895 - val_loss: 1.3661 - val_accuracy: 0.5075\n",
      "\n",
      "Epoch 00183: val_loss improved from 1.37505 to 1.36610, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 184/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 1.4816 - accuracy: 0.4007 - val_loss: 1.3790 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.36610\n",
      "Epoch 185/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 1.4527 - accuracy: 0.4457 - val_loss: 1.3729 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.36610\n",
      "Epoch 186/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 123us/step - loss: 1.4595 - accuracy: 0.4419 - val_loss: 1.3463 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00186: val_loss improved from 1.36610 to 1.34633, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 187/350\n",
      "267/267 [==============================] - 0s 110us/step - loss: 1.4604 - accuracy: 0.4082 - val_loss: 1.3402 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00187: val_loss improved from 1.34633 to 1.34024, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 188/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.5300 - accuracy: 0.4045 - val_loss: 1.3539 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.34024\n",
      "Epoch 189/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.5361 - accuracy: 0.4082 - val_loss: 1.3504 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.34024\n",
      "Epoch 190/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.4571 - accuracy: 0.4419 - val_loss: 1.3546 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.34024\n",
      "Epoch 191/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4700 - accuracy: 0.4307 - val_loss: 1.3576 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.34024\n",
      "Epoch 192/350\n",
      "267/267 [==============================] - 0s 99us/step - loss: 1.4353 - accuracy: 0.4419 - val_loss: 1.3424 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.34024\n",
      "Epoch 193/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.5048 - accuracy: 0.4007 - val_loss: 1.3363 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00193: val_loss improved from 1.34024 to 1.33631, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 194/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.4605 - accuracy: 0.4270 - val_loss: 1.3408 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.33631\n",
      "Epoch 195/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.4817 - accuracy: 0.4195 - val_loss: 1.3404 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.33631\n",
      "Epoch 196/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.4511 - accuracy: 0.4345 - val_loss: 1.3558 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.33631\n",
      "Epoch 197/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 1.4851 - accuracy: 0.4157 - val_loss: 1.3545 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.33631\n",
      "Epoch 198/350\n",
      "267/267 [==============================] - 0s 110us/step - loss: 1.4279 - accuracy: 0.4532 - val_loss: 1.3337 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00198: val_loss improved from 1.33631 to 1.33366, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 199/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4307 - accuracy: 0.4307 - val_loss: 1.3106 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00199: val_loss improved from 1.33366 to 1.31064, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 200/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 1.4608 - accuracy: 0.4345 - val_loss: 1.3007 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00200: val_loss improved from 1.31064 to 1.30069, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 201/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.4153 - accuracy: 0.4569 - val_loss: 1.2962 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00201: val_loss improved from 1.30069 to 1.29616, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 202/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.4970 - accuracy: 0.4232 - val_loss: 1.2901 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00202: val_loss improved from 1.29616 to 1.29007, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 203/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.4109 - accuracy: 0.4157 - val_loss: 1.2980 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.29007\n",
      "Epoch 204/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.3915 - accuracy: 0.4494 - val_loss: 1.2904 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.29007\n",
      "Epoch 205/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.4207 - accuracy: 0.4345 - val_loss: 1.3003 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1.29007\n",
      "Epoch 206/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4011 - accuracy: 0.4195 - val_loss: 1.3097 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.29007\n",
      "Epoch 207/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.3415 - accuracy: 0.4682 - val_loss: 1.3038 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1.29007\n",
      "Epoch 208/350\n",
      "267/267 [==============================] - 0s 79us/step - loss: 1.4330 - accuracy: 0.4345 - val_loss: 1.3063 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.29007\n",
      "Epoch 209/350\n",
      "267/267 [==============================] - 0s 109us/step - loss: 1.3750 - accuracy: 0.4419 - val_loss: 1.3067 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.29007\n",
      "Epoch 210/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4138 - accuracy: 0.4120 - val_loss: 1.2935 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.29007\n",
      "Epoch 211/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4711 - accuracy: 0.4082 - val_loss: 1.2941 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.29007\n",
      "Epoch 212/350\n",
      "267/267 [==============================] - 0s 94us/step - loss: 1.3452 - accuracy: 0.4270 - val_loss: 1.2738 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00212: val_loss improved from 1.29007 to 1.27378, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 213/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4022 - accuracy: 0.4007 - val_loss: 1.2614 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00213: val_loss improved from 1.27378 to 1.26137, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 214/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.4395 - accuracy: 0.3858 - val_loss: 1.2835 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1.26137\n",
      "Epoch 215/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.4109 - accuracy: 0.3970 - val_loss: 1.2899 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.26137\n",
      "Epoch 216/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.3824 - accuracy: 0.4569 - val_loss: 1.2929 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 1.26137\n",
      "Epoch 217/350\n",
      "267/267 [==============================] - 0s 176us/step - loss: 1.3846 - accuracy: 0.4419 - val_loss: 1.2649 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 1.26137\n",
      "Epoch 218/350\n",
      "267/267 [==============================] - 0s 176us/step - loss: 1.3640 - accuracy: 0.4419 - val_loss: 1.2513 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00218: val_loss improved from 1.26137 to 1.25133, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 219/350\n",
      "267/267 [==============================] - 0s 125us/step - loss: 1.2763 - accuracy: 0.4831 - val_loss: 1.2594 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.25133\n",
      "Epoch 220/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.3346 - accuracy: 0.4419 - val_loss: 1.2470 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00220: val_loss improved from 1.25133 to 1.24698, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 221/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 1.3589 - accuracy: 0.4419 - val_loss: 1.2269 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00221: val_loss improved from 1.24698 to 1.22694, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 222/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 1.3384 - accuracy: 0.4457 - val_loss: 1.2266 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00222: val_loss improved from 1.22694 to 1.22659, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 223/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 123us/step - loss: 1.3204 - accuracy: 0.4682 - val_loss: 1.2244 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00223: val_loss improved from 1.22659 to 1.22440, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 224/350\n",
      "267/267 [==============================] - 0s 146us/step - loss: 1.3516 - accuracy: 0.4419 - val_loss: 1.2334 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 1.22440\n",
      "Epoch 225/350\n",
      "267/267 [==============================] - 0s 142us/step - loss: 1.3739 - accuracy: 0.4195 - val_loss: 1.2116 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00225: val_loss improved from 1.22440 to 1.21155, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 226/350\n",
      "267/267 [==============================] - 0s 149us/step - loss: 1.3117 - accuracy: 0.4831 - val_loss: 1.2194 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1.21155\n",
      "Epoch 227/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 1.3327 - accuracy: 0.4345 - val_loss: 1.2449 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 1.21155\n",
      "Epoch 228/350\n",
      "267/267 [==============================] - 0s 129us/step - loss: 1.3137 - accuracy: 0.4419 - val_loss: 1.2422 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 1.21155\n",
      "Epoch 229/350\n",
      "267/267 [==============================] - 0s 146us/step - loss: 1.3314 - accuracy: 0.4569 - val_loss: 1.2450 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 1.21155\n",
      "Epoch 230/350\n",
      "267/267 [==============================] - 0s 135us/step - loss: 1.3502 - accuracy: 0.4569 - val_loss: 1.2445 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1.21155\n",
      "Epoch 231/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.3172 - accuracy: 0.4232 - val_loss: 1.2286 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1.21155\n",
      "Epoch 232/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.3496 - accuracy: 0.4382 - val_loss: 1.2330 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1.21155\n",
      "Epoch 233/350\n",
      "267/267 [==============================] - 0s 149us/step - loss: 1.3700 - accuracy: 0.4607 - val_loss: 1.2304 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1.21155\n",
      "Epoch 234/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 1.3316 - accuracy: 0.4457 - val_loss: 1.2343 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1.21155\n",
      "Epoch 235/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.3400 - accuracy: 0.4457 - val_loss: 1.2286 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1.21155\n",
      "Epoch 236/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.2996 - accuracy: 0.4532 - val_loss: 1.2253 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1.21155\n",
      "Epoch 237/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.2534 - accuracy: 0.4682 - val_loss: 1.2102 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00237: val_loss improved from 1.21155 to 1.21018, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 238/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.2893 - accuracy: 0.4757 - val_loss: 1.1867 - val_accuracy: 0.5224\n",
      "\n",
      "Epoch 00238: val_loss improved from 1.21018 to 1.18668, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 239/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.3570 - accuracy: 0.4494 - val_loss: 1.1895 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1.18668\n",
      "Epoch 240/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.2854 - accuracy: 0.4532 - val_loss: 1.2124 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1.18668\n",
      "Epoch 241/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 1.3590 - accuracy: 0.4307 - val_loss: 1.2117 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1.18668\n",
      "Epoch 242/350\n",
      "267/267 [==============================] - 0s 187us/step - loss: 1.3201 - accuracy: 0.4120 - val_loss: 1.2103 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1.18668\n",
      "Epoch 243/350\n",
      "267/267 [==============================] - 0s 161us/step - loss: 1.2859 - accuracy: 0.4719 - val_loss: 1.2082 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1.18668\n",
      "Epoch 244/350\n",
      "267/267 [==============================] - 0s 139us/step - loss: 1.2944 - accuracy: 0.4607 - val_loss: 1.1855 - val_accuracy: 0.4179\n",
      "\n",
      "Epoch 00244: val_loss improved from 1.18668 to 1.18549, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 245/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.3285 - accuracy: 0.4457 - val_loss: 1.1877 - val_accuracy: 0.4179\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1.18549\n",
      "Epoch 246/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.2729 - accuracy: 0.4794 - val_loss: 1.2113 - val_accuracy: 0.4179\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1.18549\n",
      "Epoch 247/350\n",
      "267/267 [==============================] - 0s 153us/step - loss: 1.2381 - accuracy: 0.4794 - val_loss: 1.2077 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1.18549\n",
      "Epoch 248/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.2844 - accuracy: 0.4382 - val_loss: 1.1938 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1.18549\n",
      "Epoch 249/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 1.2369 - accuracy: 0.4794 - val_loss: 1.1992 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1.18549\n",
      "Epoch 250/350\n",
      "267/267 [==============================] - 0s 176us/step - loss: 1.2321 - accuracy: 0.4794 - val_loss: 1.1971 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1.18549\n",
      "Epoch 251/350\n",
      "267/267 [==============================] - 0s 168us/step - loss: 1.2852 - accuracy: 0.4494 - val_loss: 1.1769 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00251: val_loss improved from 1.18549 to 1.17686, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 252/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 1.2348 - accuracy: 0.4532 - val_loss: 1.1890 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1.17686\n",
      "Epoch 253/350\n",
      "267/267 [==============================] - 0s 131us/step - loss: 1.2605 - accuracy: 0.4494 - val_loss: 1.1975 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1.17686\n",
      "Epoch 254/350\n",
      "267/267 [==============================] - 0s 120us/step - loss: 1.2160 - accuracy: 0.4831 - val_loss: 1.1850 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1.17686\n",
      "Epoch 255/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 1.3061 - accuracy: 0.4494 - val_loss: 1.1798 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1.17686\n",
      "Epoch 256/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 1.2409 - accuracy: 0.4419 - val_loss: 1.1814 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1.17686\n",
      "Epoch 257/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.2180 - accuracy: 0.4719 - val_loss: 1.1504 - val_accuracy: 0.4478\n",
      "\n",
      "Epoch 00257: val_loss improved from 1.17686 to 1.15045, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 258/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.1830 - accuracy: 0.4831 - val_loss: 1.1346 - val_accuracy: 0.4179\n",
      "\n",
      "Epoch 00258: val_loss improved from 1.15045 to 1.13458, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 259/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.2940 - accuracy: 0.4419 - val_loss: 1.1352 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1.13458\n",
      "Epoch 260/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.2168 - accuracy: 0.4719 - val_loss: 1.1214 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00260: val_loss improved from 1.13458 to 1.12142, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 261/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.1959 - accuracy: 0.5019 - val_loss: 1.1135 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00261: val_loss improved from 1.12142 to 1.11355, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 262/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.1933 - accuracy: 0.5019 - val_loss: 1.1196 - val_accuracy: 0.5373\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.11355\n",
      "Epoch 263/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.1987 - accuracy: 0.4906 - val_loss: 1.1311 - val_accuracy: 0.4925\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1.11355\n",
      "Epoch 264/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1930 - accuracy: 0.4644 - val_loss: 1.1274 - val_accuracy: 0.5224\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1.11355\n",
      "Epoch 265/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.1917 - accuracy: 0.4644 - val_loss: 1.1206 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1.11355\n",
      "Epoch 266/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.2046 - accuracy: 0.4757 - val_loss: 1.1361 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1.11355\n",
      "Epoch 267/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.2227 - accuracy: 0.4981 - val_loss: 1.1007 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00267: val_loss improved from 1.11355 to 1.10074, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 268/350\n",
      "267/267 [==============================] - 0s 88us/step - loss: 1.1753 - accuracy: 0.4794 - val_loss: 1.0887 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00268: val_loss improved from 1.10074 to 1.08867, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 269/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 1.2130 - accuracy: 0.4532 - val_loss: 1.1153 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1.08867\n",
      "Epoch 270/350\n",
      "267/267 [==============================] - 0s 150us/step - loss: 1.1777 - accuracy: 0.4757 - val_loss: 1.1015 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1.08867\n",
      "Epoch 271/350\n",
      "267/267 [==============================] - 0s 134us/step - loss: 1.1842 - accuracy: 0.4944 - val_loss: 1.0927 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1.08867\n",
      "Epoch 272/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 1.3038 - accuracy: 0.4607 - val_loss: 1.1019 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1.08867\n",
      "Epoch 273/350\n",
      "267/267 [==============================] - 0s 209us/step - loss: 1.1603 - accuracy: 0.4981 - val_loss: 1.1110 - val_accuracy: 0.4328\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1.08867\n",
      "Epoch 274/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.2214 - accuracy: 0.4944 - val_loss: 1.0871 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00274: val_loss improved from 1.08867 to 1.08708, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 275/350\n",
      "267/267 [==============================] - 0s 78us/step - loss: 1.1521 - accuracy: 0.4981 - val_loss: 1.0706 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00275: val_loss improved from 1.08708 to 1.07055, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 276/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.1440 - accuracy: 0.4981 - val_loss: 1.0723 - val_accuracy: 0.5373\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1.07055\n",
      "Epoch 277/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.1780 - accuracy: 0.4831 - val_loss: 1.0827 - val_accuracy: 0.4776\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1.07055\n",
      "Epoch 278/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.1628 - accuracy: 0.4794 - val_loss: 1.0551 - val_accuracy: 0.5672\n",
      "\n",
      "Epoch 00278: val_loss improved from 1.07055 to 1.05509, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 279/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1504 - accuracy: 0.4719 - val_loss: 1.0812 - val_accuracy: 0.4627\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1.05509\n",
      "Epoch 280/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.1279 - accuracy: 0.5281 - val_loss: 1.0607 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1.05509\n",
      "Epoch 281/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.2048 - accuracy: 0.4831 - val_loss: 1.0542 - val_accuracy: 0.5821\n",
      "\n",
      "Epoch 00281: val_loss improved from 1.05509 to 1.05419, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 282/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1393 - accuracy: 0.5431 - val_loss: 1.0541 - val_accuracy: 0.5373\n",
      "\n",
      "Epoch 00282: val_loss improved from 1.05419 to 1.05415, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 283/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.1531 - accuracy: 0.5356 - val_loss: 1.0466 - val_accuracy: 0.5970\n",
      "\n",
      "Epoch 00283: val_loss improved from 1.05415 to 1.04660, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 284/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1071 - accuracy: 0.5393 - val_loss: 1.0482 - val_accuracy: 0.5672\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1.04660\n",
      "Epoch 285/350\n",
      "267/267 [==============================] - 0s 94us/step - loss: 1.1589 - accuracy: 0.5056 - val_loss: 1.0073 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00285: val_loss improved from 1.04660 to 1.00732, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 286/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.1225 - accuracy: 0.5318 - val_loss: 0.9948 - val_accuracy: 0.6269\n",
      "\n",
      "Epoch 00286: val_loss improved from 1.00732 to 0.99478, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 287/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.1862 - accuracy: 0.5019 - val_loss: 0.9957 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.99478\n",
      "Epoch 288/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.0799 - accuracy: 0.5506 - val_loss: 0.9825 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.99478 to 0.98253, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 289/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.1825 - accuracy: 0.5169 - val_loss: 0.9952 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.98253\n",
      "Epoch 290/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1537 - accuracy: 0.5169 - val_loss: 1.0103 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.98253\n",
      "Epoch 291/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1448 - accuracy: 0.5169 - val_loss: 0.9736 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.98253 to 0.97356, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 292/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.0738 - accuracy: 0.5468 - val_loss: 0.9854 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.97356\n",
      "Epoch 293/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 1.1520 - accuracy: 0.5356 - val_loss: 0.9736 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.97356\n",
      "Epoch 294/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.1274 - accuracy: 0.5506 - val_loss: 0.9729 - val_accuracy: 0.5821\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.97356 to 0.97286, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 295/350\n",
      "267/267 [==============================] - 0s 75us/step - loss: 1.1407 - accuracy: 0.5318 - val_loss: 0.9539 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.97286 to 0.95385, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 296/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.1187 - accuracy: 0.5468 - val_loss: 0.9685 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.95385\n",
      "Epoch 297/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.0822 - accuracy: 0.5618 - val_loss: 0.9419 - val_accuracy: 0.6716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00297: val_loss improved from 0.95385 to 0.94186, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 298/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.1245 - accuracy: 0.5131 - val_loss: 0.9291 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.94186 to 0.92909, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 299/350\n",
      "267/267 [==============================] - 0s 82us/step - loss: 1.0358 - accuracy: 0.5993 - val_loss: 0.9208 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.92909 to 0.92079, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 300/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.0791 - accuracy: 0.5543 - val_loss: 0.9117 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.92079 to 0.91166, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 301/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.0906 - accuracy: 0.5506 - val_loss: 0.9698 - val_accuracy: 0.5970\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.91166\n",
      "Epoch 302/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.0768 - accuracy: 0.5468 - val_loss: 0.9409 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.91166\n",
      "Epoch 303/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 1.0774 - accuracy: 0.5318 - val_loss: 0.9338 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.91166\n",
      "Epoch 304/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.0448 - accuracy: 0.5730 - val_loss: 0.9314 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.91166\n",
      "Epoch 305/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.0493 - accuracy: 0.5730 - val_loss: 0.9016 - val_accuracy: 0.5970\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.91166 to 0.90157, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 306/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.0894 - accuracy: 0.5243 - val_loss: 0.8853 - val_accuracy: 0.6269\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.90157 to 0.88528, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 307/350\n",
      "267/267 [==============================] - 0s 78us/step - loss: 1.0467 - accuracy: 0.5506 - val_loss: 0.8478 - val_accuracy: 0.5672\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.88528 to 0.84776, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 308/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.1160 - accuracy: 0.5431 - val_loss: 0.8868 - val_accuracy: 0.5672\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.84776\n",
      "Epoch 309/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.0577 - accuracy: 0.5506 - val_loss: 0.9386 - val_accuracy: 0.5224\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.84776\n",
      "Epoch 310/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.0303 - accuracy: 0.6030 - val_loss: 0.8871 - val_accuracy: 0.6269\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.84776\n",
      "Epoch 311/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.0598 - accuracy: 0.5543 - val_loss: 0.8615 - val_accuracy: 0.6866\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.84776\n",
      "Epoch 312/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 1.0392 - accuracy: 0.5693 - val_loss: 0.8645 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.84776\n",
      "Epoch 313/350\n",
      "267/267 [==============================] - 0s 123us/step - loss: 1.0233 - accuracy: 0.5581 - val_loss: 0.8898 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.84776\n",
      "Epoch 314/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 1.0264 - accuracy: 0.5393 - val_loss: 0.8588 - val_accuracy: 0.7164\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.84776\n",
      "Epoch 315/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 0.9921 - accuracy: 0.5805 - val_loss: 0.8433 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.84776 to 0.84331, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 316/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 1.0013 - accuracy: 0.5918 - val_loss: 0.8290 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.84331 to 0.82903, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 317/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 1.0114 - accuracy: 0.5730 - val_loss: 0.7949 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.82903 to 0.79487, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 318/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 0.9069 - accuracy: 0.5993 - val_loss: 0.7839 - val_accuracy: 0.6866\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.79487 to 0.78387, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 319/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 1.0121 - accuracy: 0.5843 - val_loss: 0.8338 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.78387\n",
      "Epoch 320/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.9624 - accuracy: 0.6217 - val_loss: 0.8298 - val_accuracy: 0.6269\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.78387\n",
      "Epoch 321/350\n",
      "267/267 [==============================] - 0s 116us/step - loss: 1.0689 - accuracy: 0.5880 - val_loss: 0.7966 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.78387\n",
      "Epoch 322/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 0.9358 - accuracy: 0.5955 - val_loss: 0.8109 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.78387\n",
      "Epoch 323/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 0.9781 - accuracy: 0.5880 - val_loss: 0.8172 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.78387\n",
      "Epoch 324/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 0.9539 - accuracy: 0.5880 - val_loss: 0.7801 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.78387 to 0.78013, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 325/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 0.9760 - accuracy: 0.5693 - val_loss: 0.7816 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.78013\n",
      "Epoch 326/350\n",
      "267/267 [==============================] - 0s 86us/step - loss: 0.9955 - accuracy: 0.5618 - val_loss: 0.8308 - val_accuracy: 0.5970\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.78013\n",
      "Epoch 327/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.9046 - accuracy: 0.5955 - val_loss: 0.7943 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.78013\n",
      "Epoch 328/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 0.9528 - accuracy: 0.5805 - val_loss: 0.8585 - val_accuracy: 0.5821\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.78013\n",
      "Epoch 329/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 0.9904 - accuracy: 0.5880 - val_loss: 0.8913 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.78013\n",
      "Epoch 330/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 1.0045 - accuracy: 0.5805 - val_loss: 0.7925 - val_accuracy: 0.6866\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.78013\n",
      "Epoch 331/350\n",
      "267/267 [==============================] - 0s 115us/step - loss: 0.9798 - accuracy: 0.5955 - val_loss: 0.7812 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.78013\n",
      "Epoch 332/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 0.9070 - accuracy: 0.6142 - val_loss: 0.8288 - val_accuracy: 0.6866\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.78013\n",
      "Epoch 333/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 0.9093 - accuracy: 0.5993 - val_loss: 0.7748 - val_accuracy: 0.6866\n",
      "\n",
      "Epoch 00333: val_loss improved from 0.78013 to 0.77483, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 334/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 0.9646 - accuracy: 0.6067 - val_loss: 0.7672 - val_accuracy: 0.7463\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.77483 to 0.76725, saving model to saved_models/weights.best.basic_mlp.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.9242 - accuracy: 0.6030 - val_loss: 0.7492 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.76725 to 0.74920, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 336/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.8972 - accuracy: 0.6217 - val_loss: 0.7206 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.74920 to 0.72056, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 337/350\n",
      "267/267 [==============================] - 0s 101us/step - loss: 0.8719 - accuracy: 0.6292 - val_loss: 0.7557 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.72056\n",
      "Epoch 338/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.9758 - accuracy: 0.6142 - val_loss: 0.7456 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.72056\n",
      "Epoch 339/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.9079 - accuracy: 0.6105 - val_loss: 0.7151 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.72056 to 0.71514, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 340/350\n",
      "267/267 [==============================] - 0s 157us/step - loss: 0.9439 - accuracy: 0.5843 - val_loss: 0.7135 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.71514 to 0.71353, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 341/350\n",
      "267/267 [==============================] - 0s 138us/step - loss: 0.8939 - accuracy: 0.6592 - val_loss: 0.7406 - val_accuracy: 0.7463\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.71353\n",
      "Epoch 342/350\n",
      "267/267 [==============================] - 0s 112us/step - loss: 0.9113 - accuracy: 0.6180 - val_loss: 0.7469 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.71353\n",
      "Epoch 343/350\n",
      "267/267 [==============================] - 0s 127us/step - loss: 0.8548 - accuracy: 0.6330 - val_loss: 0.7114 - val_accuracy: 0.7164\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.71353 to 0.71145, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 344/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 0.8963 - accuracy: 0.6105 - val_loss: 0.6993 - val_accuracy: 0.7463\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.71145 to 0.69925, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 345/350\n",
      "267/267 [==============================] - 0s 108us/step - loss: 0.8967 - accuracy: 0.6180 - val_loss: 0.6996 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.69925\n",
      "Epoch 346/350\n",
      "267/267 [==============================] - 0s 97us/step - loss: 0.8937 - accuracy: 0.6367 - val_loss: 0.6922 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.69925 to 0.69225, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 347/350\n",
      "267/267 [==============================] - 0s 93us/step - loss: 0.9435 - accuracy: 0.6404 - val_loss: 0.6916 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.69225 to 0.69155, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 348/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 0.8985 - accuracy: 0.6105 - val_loss: 0.6995 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.69155\n",
      "Epoch 349/350\n",
      "267/267 [==============================] - 0s 90us/step - loss: 0.9020 - accuracy: 0.6292 - val_loss: 0.6728 - val_accuracy: 0.7463\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.69155 to 0.67281, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 350/350\n",
      "267/267 [==============================] - 0s 105us/step - loss: 0.8232 - accuracy: 0.6629 - val_loss: 0.6573 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.67281 to 0.65726, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Training completed in time:  0:00:16.961519\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 350\n",
    "num_batch_size = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7865168452262878\n",
      "Testing Accuracy:  0.7313432693481445\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: Education \n",
      "\n",
      "Education \t\t :  0.91404402256011962890625000000000\n",
      "Shopping \t\t :  0.00071707600727677345275878906250\n",
      "double_tap \t\t :  0.03254792094230651855468750000000\n",
      "game \t\t :  0.01222573220729827880859375000000\n",
      "long_tap \t\t :  0.00003888266655849292874336242676\n",
      "social media \t\t :  0.00524631282314658164978027343750\n",
      "swipe \t\t :  0.00016034871805459260940551757812\n",
      "tap \t\t :  0.02738735824823379516601562500000\n",
      "travel \t\t :  0.00004298471685615368187427520752\n",
      "zoom \t\t :  0.00758932018652558326721191406250\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "filename = '../dataset/audio/duo1.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
