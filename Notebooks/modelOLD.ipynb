{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  207  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = '../dataset/audio/'\n",
    "\n",
    "#metadata = pd.read_csv('../dataset/dataset.csv')\n",
    "metadata = pd.read_csv('../dataset/datasetM2.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class_name\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_train' (ndarray)\n",
      "Stored 'x_test' (ndarray)\n",
      "Stored 'y_train' (ndarray)\n",
      "Stored 'y_test' (ndarray)\n",
      "Stored 'yy' (ndarray)\n",
      "Stored 'le' (LabelEncoder)\n"
     ]
    }
   ],
   "source": [
    "### store the preprocessed data for use in the next notebook\n",
    "\n",
    "%store x_train \n",
    "%store x_test \n",
    "%store y_train \n",
    "%store y_test \n",
    "%store yy \n",
    "%store le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1285      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 77,573\n",
      "Trainable params: 77,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 45.2381%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 165 samples, validate on 42 samples\n",
      "Epoch 1/350\n",
      "165/165 [==============================] - 0s 982us/step - loss: 60.2136 - accuracy: 0.3273 - val_loss: 30.9474 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 30.94742, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 2/350\n",
      "165/165 [==============================] - 0s 81us/step - loss: 49.9171 - accuracy: 0.3697 - val_loss: 37.3315 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 30.94742\n",
      "Epoch 3/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 48.6894 - accuracy: 0.3455 - val_loss: 12.2164 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00003: val_loss improved from 30.94742 to 12.21641, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 4/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 52.4435 - accuracy: 0.2606 - val_loss: 10.0927 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00004: val_loss improved from 12.21641 to 10.09269, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 5/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 35.3555 - accuracy: 0.3636 - val_loss: 9.0302 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00005: val_loss improved from 10.09269 to 9.03017, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 6/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 30.5693 - accuracy: 0.3636 - val_loss: 10.4567 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 9.03017\n",
      "Epoch 7/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 26.3024 - accuracy: 0.4242 - val_loss: 4.4433 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00007: val_loss improved from 9.03017 to 4.44327, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 8/350\n",
      "165/165 [==============================] - 0s 73us/step - loss: 25.9278 - accuracy: 0.3818 - val_loss: 3.2480 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.44327 to 3.24803, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 9/350\n",
      "165/165 [==============================] - 0s 75us/step - loss: 22.2020 - accuracy: 0.3576 - val_loss: 5.6367 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.24803\n",
      "Epoch 10/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 21.9967 - accuracy: 0.3879 - val_loss: 4.7210 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.24803\n",
      "Epoch 11/350\n",
      "165/165 [==============================] - 0s 73us/step - loss: 18.4013 - accuracy: 0.3818 - val_loss: 4.6001 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.24803\n",
      "Epoch 12/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 18.5640 - accuracy: 0.4182 - val_loss: 4.6516 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.24803\n",
      "Epoch 13/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 14.2808 - accuracy: 0.4545 - val_loss: 4.5976 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.24803\n",
      "Epoch 14/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 12.1754 - accuracy: 0.4606 - val_loss: 3.5388 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.24803\n",
      "Epoch 15/350\n",
      "165/165 [==============================] - 0s 79us/step - loss: 12.7653 - accuracy: 0.4182 - val_loss: 2.7637 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.24803 to 2.76365, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 16/350\n",
      "165/165 [==============================] - 0s 71us/step - loss: 12.3441 - accuracy: 0.4182 - val_loss: 2.9049 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.76365\n",
      "Epoch 17/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 11.3713 - accuracy: 0.4182 - val_loss: 2.6126 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.76365 to 2.61265, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 18/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 9.9239 - accuracy: 0.4606 - val_loss: 2.0729 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.61265 to 2.07293, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 19/350\n",
      "165/165 [==============================] - 0s 83us/step - loss: 9.0384 - accuracy: 0.4424 - val_loss: 1.7240 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.07293 to 1.72404, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 20/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 9.0695 - accuracy: 0.4424 - val_loss: 1.5063 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.72404 to 1.50631, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 21/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 8.3622 - accuracy: 0.4121 - val_loss: 1.3765 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.50631 to 1.37647, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 22/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 7.7715 - accuracy: 0.4545 - val_loss: 1.1681 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.37647 to 1.16807, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 23/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 7.2737 - accuracy: 0.4424 - val_loss: 1.0965 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.16807 to 1.09647, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 24/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 6.2149 - accuracy: 0.4667 - val_loss: 1.0306 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.09647 to 1.03062, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 25/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 6.4665 - accuracy: 0.4727 - val_loss: 1.0639 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.03062\n",
      "Epoch 26/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 4.9365 - accuracy: 0.4364 - val_loss: 1.2042 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.03062\n",
      "Epoch 27/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 5.6618 - accuracy: 0.4667 - val_loss: 1.2581 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.03062\n",
      "Epoch 28/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 5.2334 - accuracy: 0.4545 - val_loss: 1.1258 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.03062\n",
      "Epoch 29/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 4.9018 - accuracy: 0.4485 - val_loss: 1.0312 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.03062\n",
      "Epoch 30/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 4.8894 - accuracy: 0.4364 - val_loss: 1.0106 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.03062 to 1.01059, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 31/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 4.1131 - accuracy: 0.4364 - val_loss: 0.9962 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.01059 to 0.99622, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 32/350\n",
      "165/165 [==============================] - 0s 71us/step - loss: 3.9629 - accuracy: 0.4606 - val_loss: 1.0013 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.99622\n",
      "Epoch 33/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 4.1169 - accuracy: 0.4424 - val_loss: 1.0188 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.99622\n",
      "Epoch 34/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 3.3547 - accuracy: 0.4970 - val_loss: 1.0263 - val_accuracy: 0.3810\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.99622\n",
      "Epoch 35/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 3.9135 - accuracy: 0.4485 - val_loss: 1.0312 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.99622\n",
      "Epoch 36/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 3.6880 - accuracy: 0.4182 - val_loss: 1.0344 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.99622\n",
      "Epoch 37/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 60us/step - loss: 3.1546 - accuracy: 0.4364 - val_loss: 1.0360 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.99622\n",
      "Epoch 38/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 3.2020 - accuracy: 0.4727 - val_loss: 1.0385 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.99622\n",
      "Epoch 39/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 2.4983 - accuracy: 0.4121 - val_loss: 1.0405 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.99622\n",
      "Epoch 40/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 2.4900 - accuracy: 0.4606 - val_loss: 1.0433 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.99622\n",
      "Epoch 41/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 2.3496 - accuracy: 0.4303 - val_loss: 1.0488 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.99622\n",
      "Epoch 42/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 2.4249 - accuracy: 0.4727 - val_loss: 1.0525 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.99622\n",
      "Epoch 43/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 2.6924 - accuracy: 0.4242 - val_loss: 1.0543 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.99622\n",
      "Epoch 44/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 2.1140 - accuracy: 0.5152 - val_loss: 1.0575 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.99622\n",
      "Epoch 45/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.8387 - accuracy: 0.4485 - val_loss: 1.0579 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.99622\n",
      "Epoch 46/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 2.1911 - accuracy: 0.4424 - val_loss: 1.0541 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.99622\n",
      "Epoch 47/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 2.4368 - accuracy: 0.4364 - val_loss: 1.0513 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.99622\n",
      "Epoch 48/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 2.2097 - accuracy: 0.4242 - val_loss: 1.0503 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.99622\n",
      "Epoch 49/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 2.0033 - accuracy: 0.4545 - val_loss: 1.0539 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.99622\n",
      "Epoch 50/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 2.3167 - accuracy: 0.3939 - val_loss: 1.0444 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.99622\n",
      "Epoch 51/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 2.0117 - accuracy: 0.4606 - val_loss: 1.0407 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.99622\n",
      "Epoch 52/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 2.0767 - accuracy: 0.4121 - val_loss: 1.0401 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.99622\n",
      "Epoch 53/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.6607 - accuracy: 0.4667 - val_loss: 1.0407 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.99622\n",
      "Epoch 54/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 1.3901 - accuracy: 0.4848 - val_loss: 1.0410 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.99622\n",
      "Epoch 55/350\n",
      "165/165 [==============================] - 0s 71us/step - loss: 1.6954 - accuracy: 0.4727 - val_loss: 1.0415 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.99622\n",
      "Epoch 56/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 1.5886 - accuracy: 0.4727 - val_loss: 1.0436 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.99622\n",
      "Epoch 57/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 1.6207 - accuracy: 0.4727 - val_loss: 1.0449 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.99622\n",
      "Epoch 58/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.7221 - accuracy: 0.4545 - val_loss: 1.0454 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.99622\n",
      "Epoch 59/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.4123 - accuracy: 0.4848 - val_loss: 1.0461 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.99622\n",
      "Epoch 60/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.5108 - accuracy: 0.4485 - val_loss: 1.0481 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.99622\n",
      "Epoch 61/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.3441 - accuracy: 0.4485 - val_loss: 1.0496 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.99622\n",
      "Epoch 62/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 1.6287 - accuracy: 0.4364 - val_loss: 1.0477 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.99622\n",
      "Epoch 63/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.3513 - accuracy: 0.5030 - val_loss: 1.0466 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.99622\n",
      "Epoch 64/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.6627 - accuracy: 0.4364 - val_loss: 1.0472 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.99622\n",
      "Epoch 65/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.3835 - accuracy: 0.4788 - val_loss: 1.0462 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.99622\n",
      "Epoch 66/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.3900 - accuracy: 0.4545 - val_loss: 1.0434 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.99622\n",
      "Epoch 67/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 1.3957 - accuracy: 0.4182 - val_loss: 1.0431 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.99622\n",
      "Epoch 68/350\n",
      "165/165 [==============================] - 0s 75us/step - loss: 1.4821 - accuracy: 0.4485 - val_loss: 1.0435 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.99622\n",
      "Epoch 69/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.4382 - accuracy: 0.4485 - val_loss: 1.0430 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.99622\n",
      "Epoch 70/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.3711 - accuracy: 0.5091 - val_loss: 1.0398 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.99622\n",
      "Epoch 71/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.3003 - accuracy: 0.4606 - val_loss: 1.0400 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.99622\n",
      "Epoch 72/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.4105 - accuracy: 0.4364 - val_loss: 1.0407 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.99622\n",
      "Epoch 73/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.4670 - accuracy: 0.4303 - val_loss: 1.0413 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.99622\n",
      "Epoch 74/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.3472 - accuracy: 0.4545 - val_loss: 1.0416 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.99622\n",
      "Epoch 75/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.2428 - accuracy: 0.4364 - val_loss: 1.0420 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.99622\n",
      "Epoch 76/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.2490 - accuracy: 0.4485 - val_loss: 1.0412 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.99622\n",
      "Epoch 77/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.2297 - accuracy: 0.5091 - val_loss: 1.0410 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.99622\n",
      "Epoch 78/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 1.3490 - accuracy: 0.4970 - val_loss: 1.0405 - val_accuracy: 0.4048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00078: val_loss did not improve from 0.99622\n",
      "Epoch 79/350\n",
      "165/165 [==============================] - 0s 75us/step - loss: 1.2536 - accuracy: 0.4970 - val_loss: 1.0400 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.99622\n",
      "Epoch 80/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.3144 - accuracy: 0.4848 - val_loss: 1.0392 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.99622\n",
      "Epoch 81/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 1.3510 - accuracy: 0.4424 - val_loss: 1.0386 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.99622\n",
      "Epoch 82/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.5453 - accuracy: 0.4909 - val_loss: 1.0382 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.99622\n",
      "Epoch 83/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1669 - accuracy: 0.4848 - val_loss: 1.0384 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.99622\n",
      "Epoch 84/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.3590 - accuracy: 0.4485 - val_loss: 1.0387 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.99622\n",
      "Epoch 85/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.1779 - accuracy: 0.4727 - val_loss: 1.0400 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.99622\n",
      "Epoch 86/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.2581 - accuracy: 0.4667 - val_loss: 1.0431 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.99622\n",
      "Epoch 87/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.3545 - accuracy: 0.5030 - val_loss: 1.0463 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.99622\n",
      "Epoch 88/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.3702 - accuracy: 0.4606 - val_loss: 1.0476 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.99622\n",
      "Epoch 89/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.3008 - accuracy: 0.4788 - val_loss: 1.0456 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.99622\n",
      "Epoch 90/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.2572 - accuracy: 0.4909 - val_loss: 1.0439 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.99622\n",
      "Epoch 91/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.2578 - accuracy: 0.5030 - val_loss: 1.0422 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.99622\n",
      "Epoch 92/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.3821 - accuracy: 0.4545 - val_loss: 1.0412 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.99622\n",
      "Epoch 93/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.2079 - accuracy: 0.5333 - val_loss: 1.0410 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.99622\n",
      "Epoch 94/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.2660 - accuracy: 0.4606 - val_loss: 1.0410 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.99622\n",
      "Epoch 95/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.3168 - accuracy: 0.5091 - val_loss: 1.0409 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.99622\n",
      "Epoch 96/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.1990 - accuracy: 0.5091 - val_loss: 1.0400 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.99622\n",
      "Epoch 97/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1842 - accuracy: 0.5091 - val_loss: 1.0402 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.99622\n",
      "Epoch 98/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1966 - accuracy: 0.4667 - val_loss: 1.0415 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.99622\n",
      "Epoch 99/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.2458 - accuracy: 0.4364 - val_loss: 1.0434 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.99622\n",
      "Epoch 100/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.2575 - accuracy: 0.4485 - val_loss: 1.0428 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.99622\n",
      "Epoch 101/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.2250 - accuracy: 0.4667 - val_loss: 1.0402 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.99622\n",
      "Epoch 102/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.2725 - accuracy: 0.4909 - val_loss: 1.0389 - val_accuracy: 0.4048\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.99622\n",
      "Epoch 103/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.1950 - accuracy: 0.5030 - val_loss: 1.0389 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.99622\n",
      "Epoch 104/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.2622 - accuracy: 0.5030 - val_loss: 1.0387 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.99622\n",
      "Epoch 105/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.2143 - accuracy: 0.4606 - val_loss: 1.0390 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.99622\n",
      "Epoch 106/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.2072 - accuracy: 0.4909 - val_loss: 1.0398 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.99622\n",
      "Epoch 107/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.1444 - accuracy: 0.5091 - val_loss: 1.0401 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.99622\n",
      "Epoch 108/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 1.1602 - accuracy: 0.4788 - val_loss: 1.0396 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.99622\n",
      "Epoch 109/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 1.1396 - accuracy: 0.5091 - val_loss: 1.0393 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.99622\n",
      "Epoch 110/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 1.1687 - accuracy: 0.4848 - val_loss: 1.0387 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.99622\n",
      "Epoch 111/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 1.1743 - accuracy: 0.5091 - val_loss: 1.0383 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.99622\n",
      "Epoch 112/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.2422 - accuracy: 0.4485 - val_loss: 1.0385 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.99622\n",
      "Epoch 113/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.2727 - accuracy: 0.4424 - val_loss: 1.0386 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.99622\n",
      "Epoch 114/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.2731 - accuracy: 0.4667 - val_loss: 1.0386 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.99622\n",
      "Epoch 115/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.1819 - accuracy: 0.4485 - val_loss: 1.0388 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.99622\n",
      "Epoch 116/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 1.1901 - accuracy: 0.5212 - val_loss: 1.0401 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.99622\n",
      "Epoch 117/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 1.1315 - accuracy: 0.4788 - val_loss: 1.0404 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.99622\n",
      "Epoch 118/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.1542 - accuracy: 0.4606 - val_loss: 1.0400 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.99622\n",
      "Epoch 119/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.2559 - accuracy: 0.4727 - val_loss: 1.0398 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.99622\n",
      "Epoch 120/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 60us/step - loss: 1.1349 - accuracy: 0.5091 - val_loss: 1.0390 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.99622\n",
      "Epoch 121/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1352 - accuracy: 0.5212 - val_loss: 1.0383 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.99622\n",
      "Epoch 122/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.2673 - accuracy: 0.4727 - val_loss: 1.0363 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.99622\n",
      "Epoch 123/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1317 - accuracy: 0.4788 - val_loss: 1.0349 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.99622\n",
      "Epoch 124/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.1152 - accuracy: 0.4788 - val_loss: 1.0345 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.99622\n",
      "Epoch 125/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1594 - accuracy: 0.5394 - val_loss: 1.0345 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.99622\n",
      "Epoch 126/350\n",
      "165/165 [==============================] - 0s 82us/step - loss: 1.1268 - accuracy: 0.4667 - val_loss: 1.0345 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.99622\n",
      "Epoch 127/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.1491 - accuracy: 0.4788 - val_loss: 1.0342 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.99622\n",
      "Epoch 128/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 1.1412 - accuracy: 0.4727 - val_loss: 1.0340 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.99622\n",
      "Epoch 129/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1768 - accuracy: 0.5212 - val_loss: 1.0341 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.99622\n",
      "Epoch 130/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.1270 - accuracy: 0.4848 - val_loss: 1.0340 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.99622\n",
      "Epoch 131/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1536 - accuracy: 0.5333 - val_loss: 1.0340 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.99622\n",
      "Epoch 132/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 1.2280 - accuracy: 0.4606 - val_loss: 1.0353 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.99622\n",
      "Epoch 133/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1661 - accuracy: 0.4970 - val_loss: 1.0370 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.99622\n",
      "Epoch 134/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.2189 - accuracy: 0.4848 - val_loss: 1.0364 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.99622\n",
      "Epoch 135/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.2257 - accuracy: 0.5212 - val_loss: 1.0350 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.99622\n",
      "Epoch 136/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1491 - accuracy: 0.5212 - val_loss: 1.0346 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.99622\n",
      "Epoch 137/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.2057 - accuracy: 0.4970 - val_loss: 1.0358 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.99622\n",
      "Epoch 138/350\n",
      "165/165 [==============================] - 0s 74us/step - loss: 1.1868 - accuracy: 0.4909 - val_loss: 1.0369 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.99622\n",
      "Epoch 139/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 1.1204 - accuracy: 0.5333 - val_loss: 1.0382 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.99622\n",
      "Epoch 140/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1287 - accuracy: 0.4727 - val_loss: 1.0388 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.99622\n",
      "Epoch 141/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.1876 - accuracy: 0.4606 - val_loss: 1.0382 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.99622\n",
      "Epoch 142/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1713 - accuracy: 0.4848 - val_loss: 1.0368 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.99622\n",
      "Epoch 143/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.0637 - accuracy: 0.5333 - val_loss: 1.0363 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.99622\n",
      "Epoch 144/350\n",
      "165/165 [==============================] - 0s 81us/step - loss: 1.1807 - accuracy: 0.5212 - val_loss: 1.0354 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.99622\n",
      "Epoch 145/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.1469 - accuracy: 0.4909 - val_loss: 1.0348 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.99622\n",
      "Epoch 146/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 1.1015 - accuracy: 0.5273 - val_loss: 1.0344 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.99622\n",
      "Epoch 147/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1806 - accuracy: 0.4788 - val_loss: 1.0363 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.99622\n",
      "Epoch 148/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1006 - accuracy: 0.4727 - val_loss: 1.0379 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.99622\n",
      "Epoch 149/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.1482 - accuracy: 0.4788 - val_loss: 1.0398 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.99622\n",
      "Epoch 150/350\n",
      "165/165 [==============================] - 0s 71us/step - loss: 1.1476 - accuracy: 0.5333 - val_loss: 1.0426 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.99622\n",
      "Epoch 151/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1126 - accuracy: 0.5030 - val_loss: 1.0459 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.99622\n",
      "Epoch 152/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.0743 - accuracy: 0.5394 - val_loss: 1.0460 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.99622\n",
      "Epoch 153/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1534 - accuracy: 0.4909 - val_loss: 1.0433 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.99622\n",
      "Epoch 154/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.0978 - accuracy: 0.4909 - val_loss: 1.0406 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.99622\n",
      "Epoch 155/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1555 - accuracy: 0.4970 - val_loss: 1.0379 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.99622\n",
      "Epoch 156/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1206 - accuracy: 0.5212 - val_loss: 1.0350 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.99622\n",
      "Epoch 157/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.0780 - accuracy: 0.5273 - val_loss: 1.0357 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.99622\n",
      "Epoch 158/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.0806 - accuracy: 0.5212 - val_loss: 1.0339 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.99622\n",
      "Epoch 159/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1520 - accuracy: 0.4909 - val_loss: 1.0280 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.99622\n",
      "Epoch 160/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1002 - accuracy: 0.4606 - val_loss: 1.0260 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.99622\n",
      "Epoch 161/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 77us/step - loss: 1.1211 - accuracy: 0.5212 - val_loss: 1.0254 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.99622\n",
      "Epoch 162/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 1.1255 - accuracy: 0.4970 - val_loss: 1.0268 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.99622\n",
      "Epoch 163/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1475 - accuracy: 0.4848 - val_loss: 1.0286 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.99622\n",
      "Epoch 164/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1307 - accuracy: 0.4909 - val_loss: 1.0313 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.99622\n",
      "Epoch 165/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1464 - accuracy: 0.4606 - val_loss: 1.0312 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.99622\n",
      "Epoch 166/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1152 - accuracy: 0.4667 - val_loss: 1.0288 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.99622\n",
      "Epoch 167/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.1501 - accuracy: 0.4848 - val_loss: 1.0282 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.99622\n",
      "Epoch 168/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1166 - accuracy: 0.5030 - val_loss: 1.0288 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.99622\n",
      "Epoch 169/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.1278 - accuracy: 0.4606 - val_loss: 1.0285 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.99622\n",
      "Epoch 170/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1167 - accuracy: 0.5091 - val_loss: 1.0248 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.99622\n",
      "Epoch 171/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1543 - accuracy: 0.4667 - val_loss: 1.0236 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.99622\n",
      "Epoch 172/350\n",
      "165/165 [==============================] - 0s 53us/step - loss: 1.1409 - accuracy: 0.5273 - val_loss: 1.0232 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.99622\n",
      "Epoch 173/350\n",
      "165/165 [==============================] - 0s 73us/step - loss: 1.1397 - accuracy: 0.5394 - val_loss: 1.0234 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.99622\n",
      "Epoch 174/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 1.0584 - accuracy: 0.5091 - val_loss: 1.0220 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.99622\n",
      "Epoch 175/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1097 - accuracy: 0.4970 - val_loss: 1.0209 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.99622\n",
      "Epoch 176/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1268 - accuracy: 0.4909 - val_loss: 1.0210 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.99622\n",
      "Epoch 177/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.1611 - accuracy: 0.4848 - val_loss: 1.0217 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.99622\n",
      "Epoch 178/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.1156 - accuracy: 0.4667 - val_loss: 1.0252 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.99622\n",
      "Epoch 179/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.0884 - accuracy: 0.5091 - val_loss: 1.0275 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.99622\n",
      "Epoch 180/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1232 - accuracy: 0.5152 - val_loss: 1.0267 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.99622\n",
      "Epoch 181/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.1094 - accuracy: 0.5152 - val_loss: 1.0259 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.99622\n",
      "Epoch 182/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1532 - accuracy: 0.5273 - val_loss: 1.0236 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.99622\n",
      "Epoch 183/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1148 - accuracy: 0.5333 - val_loss: 1.0208 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.99622\n",
      "Epoch 184/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.0641 - accuracy: 0.5212 - val_loss: 1.0205 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.99622\n",
      "Epoch 185/350\n",
      "165/165 [==============================] - 0s 71us/step - loss: 1.1293 - accuracy: 0.4667 - val_loss: 1.0201 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.99622\n",
      "Epoch 186/350\n",
      "165/165 [==============================] - 0s 73us/step - loss: 1.0801 - accuracy: 0.5333 - val_loss: 1.0208 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.99622\n",
      "Epoch 187/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 1.0808 - accuracy: 0.5273 - val_loss: 1.0184 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.99622\n",
      "Epoch 188/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.1485 - accuracy: 0.5212 - val_loss: 1.0153 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.99622\n",
      "Epoch 189/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.0780 - accuracy: 0.5212 - val_loss: 1.0121 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.99622\n",
      "Epoch 190/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1119 - accuracy: 0.4788 - val_loss: 1.0106 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.99622\n",
      "Epoch 191/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.1236 - accuracy: 0.5273 - val_loss: 1.0131 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.99622\n",
      "Epoch 192/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 1.1375 - accuracy: 0.4727 - val_loss: 1.0156 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.99622\n",
      "Epoch 193/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.1313 - accuracy: 0.5152 - val_loss: 1.0146 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.99622\n",
      "Epoch 194/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.0914 - accuracy: 0.5091 - val_loss: 1.0131 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.99622\n",
      "Epoch 195/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.1705 - accuracy: 0.4788 - val_loss: 1.0162 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.99622\n",
      "Epoch 196/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.1034 - accuracy: 0.5333 - val_loss: 1.0207 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.99622\n",
      "Epoch 197/350\n",
      "165/165 [==============================] - 0s 77us/step - loss: 1.0754 - accuracy: 0.5030 - val_loss: 1.0200 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.99622\n",
      "Epoch 198/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.0964 - accuracy: 0.5394 - val_loss: 1.0179 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.99622\n",
      "Epoch 199/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 1.1706 - accuracy: 0.5333 - val_loss: 1.0154 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.99622\n",
      "Epoch 200/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1072 - accuracy: 0.5394 - val_loss: 1.0141 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.99622\n",
      "Epoch 201/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.0342 - accuracy: 0.5636 - val_loss: 1.0107 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.99622\n",
      "Epoch 202/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 62us/step - loss: 1.0924 - accuracy: 0.5455 - val_loss: 1.0083 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.99622\n",
      "Epoch 203/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.1023 - accuracy: 0.5515 - val_loss: 1.0061 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.99622\n",
      "Epoch 204/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.0914 - accuracy: 0.5273 - val_loss: 1.0042 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.99622\n",
      "Epoch 205/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.1424 - accuracy: 0.4848 - val_loss: 1.0035 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.99622\n",
      "Epoch 206/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 1.1468 - accuracy: 0.5273 - val_loss: 1.0037 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.99622\n",
      "Epoch 207/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.0490 - accuracy: 0.5091 - val_loss: 1.0032 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.99622\n",
      "Epoch 208/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.1333 - accuracy: 0.5636 - val_loss: 1.0019 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.99622\n",
      "Epoch 209/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.0932 - accuracy: 0.4727 - val_loss: 0.9997 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.99622\n",
      "Epoch 210/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.0389 - accuracy: 0.5697 - val_loss: 0.9947 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.99622 to 0.99473, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 211/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 1.0300 - accuracy: 0.5273 - val_loss: 0.9853 - val_accuracy: 0.4524\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.99473 to 0.98532, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 212/350\n",
      "165/165 [==============================] - 0s 53us/step - loss: 1.0383 - accuracy: 0.5273 - val_loss: 0.9816 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.98532 to 0.98159, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 213/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 1.1465 - accuracy: 0.5394 - val_loss: 0.9826 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.98159\n",
      "Epoch 214/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 1.1108 - accuracy: 0.5273 - val_loss: 0.9833 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.98159\n",
      "Epoch 215/350\n",
      "165/165 [==============================] - 0s 74us/step - loss: 1.0785 - accuracy: 0.5394 - val_loss: 0.9867 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.98159\n",
      "Epoch 216/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.1492 - accuracy: 0.5273 - val_loss: 0.9844 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.98159\n",
      "Epoch 217/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.0725 - accuracy: 0.5333 - val_loss: 0.9826 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.98159\n",
      "Epoch 218/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 1.1057 - accuracy: 0.5576 - val_loss: 0.9851 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.98159\n",
      "Epoch 219/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 1.0580 - accuracy: 0.5758 - val_loss: 0.9866 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.98159\n",
      "Epoch 220/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.0592 - accuracy: 0.5212 - val_loss: 0.9887 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.98159\n",
      "Epoch 221/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.0554 - accuracy: 0.5515 - val_loss: 0.9907 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.98159\n",
      "Epoch 222/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.0448 - accuracy: 0.5515 - val_loss: 0.9928 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.98159\n",
      "Epoch 223/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.0619 - accuracy: 0.5273 - val_loss: 0.9937 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.98159\n",
      "Epoch 224/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 1.0770 - accuracy: 0.5515 - val_loss: 0.9912 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.98159\n",
      "Epoch 225/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.0726 - accuracy: 0.4727 - val_loss: 0.9899 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.98159\n",
      "Epoch 226/350\n",
      "165/165 [==============================] - 0s 89us/step - loss: 1.0448 - accuracy: 0.5758 - val_loss: 0.9921 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.98159\n",
      "Epoch 227/350\n",
      "165/165 [==============================] - 0s 84us/step - loss: 1.0343 - accuracy: 0.5455 - val_loss: 0.9900 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.98159\n",
      "Epoch 228/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 1.1439 - accuracy: 0.4970 - val_loss: 0.9854 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.98159\n",
      "Epoch 229/350\n",
      "165/165 [==============================] - 0s 71us/step - loss: 1.1035 - accuracy: 0.5030 - val_loss: 0.9816 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.98159 to 0.98157, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 230/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 1.0485 - accuracy: 0.5576 - val_loss: 0.9773 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.98157 to 0.97729, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 231/350\n",
      "165/165 [==============================] - 0s 68us/step - loss: 1.0924 - accuracy: 0.5455 - val_loss: 0.9690 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.97729 to 0.96903, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 232/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.0497 - accuracy: 0.5818 - val_loss: 0.9669 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.96903 to 0.96694, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 233/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.0782 - accuracy: 0.5333 - val_loss: 0.9631 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.96694 to 0.96308, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 234/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 1.0342 - accuracy: 0.5818 - val_loss: 0.9589 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.96308 to 0.95889, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 235/350\n",
      "165/165 [==============================] - 0s 73us/step - loss: 1.0184 - accuracy: 0.5818 - val_loss: 0.9534 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.95889 to 0.95344, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 236/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 1.0400 - accuracy: 0.5212 - val_loss: 0.9442 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.95344 to 0.94417, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 237/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.0206 - accuracy: 0.5394 - val_loss: 0.9369 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.94417 to 0.93691, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 238/350\n",
      "165/165 [==============================] - 0s 80us/step - loss: 1.0466 - accuracy: 0.5152 - val_loss: 0.9317 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.93691 to 0.93165, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 239/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 57us/step - loss: 1.0028 - accuracy: 0.5879 - val_loss: 0.9313 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.93165 to 0.93132, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 240/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.0551 - accuracy: 0.5455 - val_loss: 0.9255 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.93132 to 0.92553, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 241/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 1.0486 - accuracy: 0.5333 - val_loss: 0.9223 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.92553 to 0.92233, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 242/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.0715 - accuracy: 0.5212 - val_loss: 0.9213 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.92233 to 0.92128, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 243/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.0261 - accuracy: 0.6000 - val_loss: 0.9201 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.92128 to 0.92010, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 244/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.0394 - accuracy: 0.5333 - val_loss: 0.9119 - val_accuracy: 0.5476\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.92010 to 0.91191, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 245/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 1.0043 - accuracy: 0.5455 - val_loss: 0.9009 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.91191 to 0.90087, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 246/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.0274 - accuracy: 0.5879 - val_loss: 0.8881 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.90087 to 0.88806, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 247/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.0151 - accuracy: 0.5212 - val_loss: 0.8876 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.88806 to 0.88757, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 248/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.9960 - accuracy: 0.5515 - val_loss: 0.8910 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.88757\n",
      "Epoch 249/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 1.0469 - accuracy: 0.5697 - val_loss: 0.8973 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.88757\n",
      "Epoch 250/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.9875 - accuracy: 0.5758 - val_loss: 0.8995 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.88757\n",
      "Epoch 251/350\n",
      "165/165 [==============================] - 0s 76us/step - loss: 0.9815 - accuracy: 0.5818 - val_loss: 0.8962 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.88757\n",
      "Epoch 252/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 0.9783 - accuracy: 0.5636 - val_loss: 0.8895 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.88757\n",
      "Epoch 253/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 1.0555 - accuracy: 0.4970 - val_loss: 0.8800 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.88757 to 0.88004, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 254/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.9910 - accuracy: 0.5576 - val_loss: 0.8691 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.88004 to 0.86912, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 255/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.9799 - accuracy: 0.5818 - val_loss: 0.8632 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.86912 to 0.86322, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 256/350\n",
      "165/165 [==============================] - 0s 75us/step - loss: 0.9899 - accuracy: 0.5879 - val_loss: 0.8618 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.86322 to 0.86185, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 257/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 1.0402 - accuracy: 0.5576 - val_loss: 0.8611 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.86185 to 0.86108, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 258/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 0.9994 - accuracy: 0.5576 - val_loss: 0.8595 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.86108 to 0.85947, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 259/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.9620 - accuracy: 0.5879 - val_loss: 0.8476 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.85947 to 0.84764, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 260/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 0.9607 - accuracy: 0.5636 - val_loss: 0.8243 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.84764 to 0.82427, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 261/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.9440 - accuracy: 0.5394 - val_loss: 0.8151 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.82427 to 0.81506, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 262/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 1.0139 - accuracy: 0.5515 - val_loss: 0.8174 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.81506\n",
      "Epoch 263/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.9540 - accuracy: 0.5879 - val_loss: 0.8341 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.81506\n",
      "Epoch 264/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 0.9712 - accuracy: 0.6061 - val_loss: 0.8350 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.81506\n",
      "Epoch 265/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 0.9967 - accuracy: 0.6121 - val_loss: 0.8438 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.81506\n",
      "Epoch 266/350\n",
      "165/165 [==============================] - 0s 74us/step - loss: 0.9249 - accuracy: 0.5636 - val_loss: 0.8383 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.81506\n",
      "Epoch 267/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 0.9839 - accuracy: 0.5758 - val_loss: 0.8307 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.81506\n",
      "Epoch 268/350\n",
      "165/165 [==============================] - 0s 75us/step - loss: 0.9246 - accuracy: 0.6061 - val_loss: 0.8186 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.81506\n",
      "Epoch 269/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 1.0054 - accuracy: 0.5818 - val_loss: 0.8220 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.81506\n",
      "Epoch 270/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.9710 - accuracy: 0.6121 - val_loss: 0.8235 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.81506\n",
      "Epoch 271/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 1.0522 - accuracy: 0.5576 - val_loss: 0.8095 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.81506 to 0.80946, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 272/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.9823 - accuracy: 0.5758 - val_loss: 0.8053 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.80946 to 0.80530, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 273/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 0.8952 - accuracy: 0.6364 - val_loss: 0.8018 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.80530 to 0.80178, saving model to saved_models/weights.best.basic_mlp.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.9047 - accuracy: 0.6485 - val_loss: 0.8069 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.80178\n",
      "Epoch 275/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.9403 - accuracy: 0.6000 - val_loss: 0.7929 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.80178 to 0.79292, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 276/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.9717 - accuracy: 0.6000 - val_loss: 0.7843 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.79292 to 0.78430, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 277/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 0.8889 - accuracy: 0.6242 - val_loss: 0.7828 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.78430 to 0.78282, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 278/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.9306 - accuracy: 0.5939 - val_loss: 0.7826 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.78282 to 0.78263, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 279/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 0.9458 - accuracy: 0.6121 - val_loss: 0.7840 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.78263\n",
      "Epoch 280/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.9206 - accuracy: 0.6000 - val_loss: 0.7803 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.78263 to 0.78028, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 281/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.9183 - accuracy: 0.5939 - val_loss: 0.7676 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.78028 to 0.76764, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 282/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 0.8789 - accuracy: 0.5879 - val_loss: 0.7516 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.76764 to 0.75158, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 283/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 0.9392 - accuracy: 0.6061 - val_loss: 0.7439 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.75158 to 0.74385, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 284/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.9062 - accuracy: 0.6000 - val_loss: 0.7475 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.74385\n",
      "Epoch 285/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 0.9546 - accuracy: 0.5939 - val_loss: 0.7717 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.74385\n",
      "Epoch 286/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.9043 - accuracy: 0.5818 - val_loss: 0.7982 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.74385\n",
      "Epoch 287/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 0.9292 - accuracy: 0.6121 - val_loss: 0.8312 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.74385\n",
      "Epoch 288/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.9354 - accuracy: 0.6000 - val_loss: 0.8138 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.74385\n",
      "Epoch 289/350\n",
      "165/165 [==============================] - 0s 81us/step - loss: 0.8875 - accuracy: 0.5697 - val_loss: 0.7869 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.74385\n",
      "Epoch 290/350\n",
      "165/165 [==============================] - 0s 65us/step - loss: 0.9333 - accuracy: 0.6182 - val_loss: 0.7688 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.74385\n",
      "Epoch 291/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 0.8895 - accuracy: 0.6182 - val_loss: 0.7514 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.74385\n",
      "Epoch 292/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.8890 - accuracy: 0.5939 - val_loss: 0.7358 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.74385 to 0.73581, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 293/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.9362 - accuracy: 0.6061 - val_loss: 0.7207 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.73581 to 0.72074, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 294/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.9346 - accuracy: 0.5636 - val_loss: 0.7219 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.72074\n",
      "Epoch 295/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 0.8522 - accuracy: 0.6061 - val_loss: 0.7290 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.72074\n",
      "Epoch 296/350\n",
      "165/165 [==============================] - 0s 72us/step - loss: 0.8263 - accuracy: 0.6545 - val_loss: 0.7289 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.72074\n",
      "Epoch 297/350\n",
      "165/165 [==============================] - 0s 67us/step - loss: 0.8872 - accuracy: 0.6182 - val_loss: 0.7238 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.72074\n",
      "Epoch 298/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.8649 - accuracy: 0.5758 - val_loss: 0.7141 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.72074 to 0.71405, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 299/350\n",
      "165/165 [==============================] - 0s 55us/step - loss: 0.8402 - accuracy: 0.6485 - val_loss: 0.6911 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.71405 to 0.69112, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 300/350\n",
      "165/165 [==============================] - 0s 53us/step - loss: 0.9109 - accuracy: 0.5636 - val_loss: 0.6837 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.69112 to 0.68373, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 301/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 0.9536 - accuracy: 0.5576 - val_loss: 0.6888 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.68373\n",
      "Epoch 302/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 0.8947 - accuracy: 0.6000 - val_loss: 0.7178 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.68373\n",
      "Epoch 303/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.8627 - accuracy: 0.5758 - val_loss: 0.7408 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.68373\n",
      "Epoch 304/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.9019 - accuracy: 0.5758 - val_loss: 0.7380 - val_accuracy: 0.5476\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.68373\n",
      "Epoch 305/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.9049 - accuracy: 0.6000 - val_loss: 0.7348 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.68373\n",
      "Epoch 306/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.8205 - accuracy: 0.5758 - val_loss: 0.7353 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.68373\n",
      "Epoch 307/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.8166 - accuracy: 0.6727 - val_loss: 0.7211 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.68373\n",
      "Epoch 308/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 0.8101 - accuracy: 0.6364 - val_loss: 0.7144 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.68373\n",
      "Epoch 309/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 0.8796 - accuracy: 0.6121 - val_loss: 0.7230 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.68373\n",
      "Epoch 310/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 0.9006 - accuracy: 0.6303 - val_loss: 0.7540 - val_accuracy: 0.5952\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.68373\n",
      "Epoch 311/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 60us/step - loss: 0.8572 - accuracy: 0.6242 - val_loss: 0.7081 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.68373\n",
      "Epoch 312/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.7873 - accuracy: 0.6485 - val_loss: 0.7053 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.68373\n",
      "Epoch 313/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 0.8646 - accuracy: 0.6061 - val_loss: 0.7063 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.68373\n",
      "Epoch 314/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.8253 - accuracy: 0.6121 - val_loss: 0.6997 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.68373\n",
      "Epoch 315/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.8174 - accuracy: 0.6303 - val_loss: 0.6973 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.68373\n",
      "Epoch 316/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.8665 - accuracy: 0.6303 - val_loss: 0.7030 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.68373\n",
      "Epoch 317/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 0.7969 - accuracy: 0.6000 - val_loss: 0.6913 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.68373\n",
      "Epoch 318/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.8281 - accuracy: 0.6424 - val_loss: 0.6717 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.68373 to 0.67171, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 319/350\n",
      "165/165 [==============================] - 0s 64us/step - loss: 0.7741 - accuracy: 0.6303 - val_loss: 0.6733 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.67171\n",
      "Epoch 320/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.8444 - accuracy: 0.6303 - val_loss: 0.6759 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.67171\n",
      "Epoch 321/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.7448 - accuracy: 0.6788 - val_loss: 0.6737 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.67171\n",
      "Epoch 322/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.8210 - accuracy: 0.6242 - val_loss: 0.6826 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.67171\n",
      "Epoch 323/350\n",
      "165/165 [==============================] - 0s 85us/step - loss: 0.8548 - accuracy: 0.6242 - val_loss: 0.6911 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.67171\n",
      "Epoch 324/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 0.7985 - accuracy: 0.6727 - val_loss: 0.6860 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.67171\n",
      "Epoch 325/350\n",
      "165/165 [==============================] - 0s 54us/step - loss: 0.7762 - accuracy: 0.6727 - val_loss: 0.6799 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.67171\n",
      "Epoch 326/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.8387 - accuracy: 0.6545 - val_loss: 0.6662 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.67171 to 0.66619, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 327/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.7822 - accuracy: 0.6364 - val_loss: 0.6647 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.66619 to 0.66467, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 328/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.7416 - accuracy: 0.6606 - val_loss: 0.6673 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.66467\n",
      "Epoch 329/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.8438 - accuracy: 0.6424 - val_loss: 0.6785 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.66467\n",
      "Epoch 330/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 0.7764 - accuracy: 0.6727 - val_loss: 0.7018 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.66467\n",
      "Epoch 331/350\n",
      "165/165 [==============================] - 0s 70us/step - loss: 0.7868 - accuracy: 0.6667 - val_loss: 0.7071 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.66467\n",
      "Epoch 332/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.8023 - accuracy: 0.6303 - val_loss: 0.6995 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.66467\n",
      "Epoch 333/350\n",
      "165/165 [==============================] - 0s 60us/step - loss: 0.7601 - accuracy: 0.6242 - val_loss: 0.6778 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.66467\n",
      "Epoch 334/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 0.7905 - accuracy: 0.6242 - val_loss: 0.6677 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.66467\n",
      "Epoch 335/350\n",
      "165/165 [==============================] - 0s 61us/step - loss: 0.7893 - accuracy: 0.6485 - val_loss: 0.6585 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.66467 to 0.65850, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 336/350\n",
      "165/165 [==============================] - 0s 69us/step - loss: 0.7910 - accuracy: 0.6061 - val_loss: 0.6576 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.65850 to 0.65760, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 337/350\n",
      "165/165 [==============================] - 0s 66us/step - loss: 0.7075 - accuracy: 0.6909 - val_loss: 0.6508 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.65760 to 0.65078, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 338/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.7545 - accuracy: 0.6545 - val_loss: 0.6382 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.65078 to 0.63820, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 339/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 0.7510 - accuracy: 0.6606 - val_loss: 0.6216 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.63820 to 0.62161, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 340/350\n",
      "165/165 [==============================] - 0s 59us/step - loss: 0.7972 - accuracy: 0.5939 - val_loss: 0.6207 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.62161 to 0.62072, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 341/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 0.7762 - accuracy: 0.6364 - val_loss: 0.6407 - val_accuracy: 0.7381\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.62072\n",
      "Epoch 342/350\n",
      "165/165 [==============================] - 0s 63us/step - loss: 0.9038 - accuracy: 0.6121 - val_loss: 0.6449 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.62072\n",
      "Epoch 343/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 0.7721 - accuracy: 0.6909 - val_loss: 0.6358 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.62072\n",
      "Epoch 344/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.7833 - accuracy: 0.6303 - val_loss: 0.6304 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.62072\n",
      "Epoch 345/350\n",
      "165/165 [==============================] - 0s 58us/step - loss: 0.7356 - accuracy: 0.6970 - val_loss: 0.6497 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.62072\n",
      "Epoch 346/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.7543 - accuracy: 0.6667 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.62072\n",
      "Epoch 347/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.7733 - accuracy: 0.6970 - val_loss: 0.6508 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.62072\n",
      "Epoch 348/350\n",
      "165/165 [==============================] - 0s 62us/step - loss: 0.7332 - accuracy: 0.6848 - val_loss: 0.6628 - val_accuracy: 0.6429\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.62072\n",
      "Epoch 349/350\n",
      "165/165 [==============================] - 0s 56us/step - loss: 0.7092 - accuracy: 0.7152 - val_loss: 0.6654 - val_accuracy: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00349: val_loss did not improve from 0.62072\n",
      "Epoch 350/350\n",
      "165/165 [==============================] - 0s 57us/step - loss: 0.7790 - accuracy: 0.6788 - val_loss: 0.6400 - val_accuracy: 0.6905\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.62072\n",
      "Training completed in time:  0:00:06.451447\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 350\n",
    "num_batch_size = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7333333492279053\n",
      "Testing Accuracy:  0.6904761791229248\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_feature(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: tap \n",
      "\n",
      "double_tap \t\t :  0.40343210101127624511718750000000\n",
      "long_tap \t\t :  0.00316147739067673683166503906250\n",
      "swipe \t\t :  0.07973125576972961425781250000000\n",
      "tap \t\t :  0.50079238414764404296875000000000\n",
      "zoom \t\t :  0.01288282033056020736694335937500\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "filename = '../dataset/audio/ebtest.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
